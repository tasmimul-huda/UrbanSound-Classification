{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994d70df-447f-46da-a6f9-cfc8b424ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd025244-cf72-4c1b-8c43-14489de925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"D:/THESIS/Spectrogram/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0553a1d-e8b2-42c6-9c28-11d258822f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_conditioner',\n",
       " 'car_horn',\n",
       " 'children_playing',\n",
       " 'dog_bark',\n",
       " 'drilling',\n",
       " 'engine_idling',\n",
       " 'gun_shot',\n",
       " 'jackhammer',\n",
       " 'siren',\n",
       " 'street_music']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = os.listdir(DATADIR)\n",
    "categories"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8488b4f7-4123-4ab3-85cd-4789cf21d9fa",
   "metadata": {},
   "source": [
    "for category in categories:  # do dogs and cats\n",
    "    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "    for i,img in enumerate(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "        img_array = cv2.imread(os.path.join(path,img) ) #,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        print(img_array.shape)\n",
    "        plt.imshow(img_array)  # graph it\n",
    "        cropped_image = img_array[34:252, 53:389]\n",
    "        print(cropped_image.shape)\n",
    "        plt.imshow(cropped_image)\n",
    "        plt.show()  # display!\n",
    "\n",
    "        break  # we just want one for now so break\n",
    "    break  #...and one more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761cebc0-bc5c-442a-9c3c-ed92fbda2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def create_dataset():\n",
    "    for category in categories:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = categories.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img)) ##,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                #rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                new_array =img_array[34:252, 53:389]\n",
    "                #print(new_array.shape)\n",
    "                rsz=cv2.resize(new_array, (224, 224))\n",
    "                #print(rsz.shape)\n",
    "                data.append([rsz, class_num])  # add this to our training_data\n",
    "                #plt.axis('off')\n",
    "                #plt.imshow(rsz)\n",
    "                #plt.savefig(\"ragresize.png\")\n",
    "                #break\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96e30d1e-eb10-4497-b5b3-88fc193548d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 57.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 429/429 [00:08<00:00, 53.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:16<00:00, 61.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:19<00:00, 51.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 55.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:16<00:00, 58.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 374/374 [00:06<00:00, 54.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 57.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 929/929 [00:16<00:00, 57.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 52.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = create_dataset()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b6870e-d605-4a14-a18f-18e5c8f7c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f52e970-4a64-436b-a9e8-2427e15d4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd272621-3aca-4911-8566-1b92e3845e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X_DATA_224x224.pickle\",\"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y_DATA_224x224.pickle\",\"wb\")\n",
    "pickle.dump(Y,pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0758932-7977-4da3-8b0d-0fcd69810bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4155bed6-891f-45c5-a057-91dba746f41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 100, 100, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e01311-5263-41cc-89df-ad0d86a95430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f35514-8f6f-46ba-9ccb-1a6d7f4ed945",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, X_test, Y_data, Y_test = train_test_split(X, Y,test_size=0.10, random_state = 42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7fd8265-8ca4-4916-beea-fd104e6da513",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val, Y_train, Y_val = train_test_split(X_data, Y_data,test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "345fe691-6a3d-4641-96fc-3c36f8b783f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizaze_data(X):\n",
    "    X_data = []\n",
    "    for data in X:\n",
    "        data = data / 255\n",
    "        X_data.append(data)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c479db90-c8b5-436b-8a73-d55f6db97951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = normalizaze_data(X_train)\n",
    "x_val = normalizaze_data(X_val)\n",
    "x_test = normalizaze_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b76f186f-b4be-45c9-b672-01ee84ea4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 100, 100, 3)\n",
    "x_val = x_val.reshape(-1, 100, 100, 3)\n",
    "x_test = x_test.reshape(-1, 100, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f1df50-d25c-47bd-8f70-a92210b376e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train =to_categorical(Y_train)\n",
    "y_val = to_categorical(Y_val)\n",
    "y_test =to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e71c96-2c68-48f4-bda9-997f198d9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (6286, 100, 100, 3)\n",
      "y_train.shape: (6286, 10)\n",
      "x_val.shape: (1572, 100, 100, 3)\n",
      "y_val.shape: (1572, 10)\n",
      "x_test.shape: (874, 100, 100, 3)\n",
      "y_test.shape: (874, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train.shape: {x_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"x_val.shape: {x_val.shape}\")\n",
    "print(f\"y_val.shape: {y_val.shape}\")\n",
    "print(f\"x_test.shape: {x_test.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7303bf6-a8ec-4505-ae8b-29c69b71050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"x_train_200X200.pickle\",\"wb\")\n",
    "pickle.dump(x_train,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_train_200X200.pickle\",\"wb\")\n",
    "pickle.dump(y_train,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"x_val_200X200.pickle\",\"wb\")\n",
    "pickle.dump(x_val,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_val_200X200.pickle\",\"wb\")\n",
    "pickle.dump(y_val,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"x_test_200X200.pickle\",\"wb\")\n",
    "pickle.dump(x_test,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_test_200X200.pickle\",\"wb\")\n",
    "pickle.dump(y_test,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188afb8-7452-4197-a74e-ac881e144a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a43de1f5-5c5a-40d2-9955-e0eef0fa99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing other required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import losses, models, optimizers\n",
    "import time\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "465fe724-15c7-4537-bd58-2f03d168ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pickle.load(open(\"x_train_200X200.pickle\",'rb'))\n",
    "y_train = pickle.load(open(\"y_train_200X200.pickle\",'rb'))\n",
    "\n",
    "x_val = pickle.load(open(\"x_val_200X200.pickle\",'rb'))\n",
    "y_val = pickle.load(open(\"y_val_200X200.pickle\",'rb'))\n",
    "\n",
    "x_test = pickle.load(open(\"x_test_200X200.pickle\",'rb'))\n",
    "y_test = pickle.load(open(\"y_test_200X200.pickle\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66882344-4c81-4af4-bc90-cbcbb1a7fc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (6286, 100, 100, 3)\n",
      "y_train.shape: (6286, 10)\n",
      "x_val.shape: (1572, 100, 100, 3)\n",
      "y_val.shape: (1572, 10)\n",
      "x_val.shape: (874, 100, 100, 3)\n",
      "y_val.shape: (874, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train.shape: {x_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"x_val.shape: {x_val.shape}\")\n",
    "print(f\"y_val.shape: {y_val.shape}\")\n",
    "print(f\"x_val.shape: {x_test.shape}\")\n",
    "print(f\"y_val.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e42e6ca7-63e4-4267-b06b-1c4397665a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "val_generator = ImageDataGenerator(rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "test_generator = ImageDataGenerator(rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "238129ce-45f5-4a0e-ae5f-f8181b303828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "\n",
    "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da827f51-4a8c-41f9-aa55-9868a1bd8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install keras_efficientnets\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c43395-b7d0-40c7-8e35-a4da9f492b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 4, 4, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20480)             0         \n",
      "=================================================================\n",
      "Total params: 4,049,571\n",
      "Trainable params: 4,007,548\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 4, 4, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20480)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               5243136   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,326,893\n",
      "Trainable params: 9,284,870\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining the model\n",
    "base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=x_train.shape[1:],classes=y_train.shape[1])\n",
    "\n",
    "#Adding the final layers to the above base models where the actual classification is done in the dense layers\n",
    "\n",
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten()) \n",
    "\n",
    "#Model summary\n",
    "model.summary()\n",
    "\n",
    "#Adding the Dense layers along with activation and batch normalization\n",
    "#model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "#model.add(Dropout(.5))\n",
    "#model.add(Dense(512,activation=('relu'))) \n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "#model.add(Dropout(.3))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(10,activation=('softmax'))) \n",
    "\n",
    "#Checking the final model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24cef234-b8d4-4ae6-a63e-79918188b6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizer_v2.adam.Adam at 0x14120aea400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977bc46-4951-4bb5-9226-549a5e9d5f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd2d0694-ec51-4dfa-98be-36ed500761ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the parameters\n",
    "batch_size= 64\n",
    "epochs=150\n",
    "learn_rate=.001\n",
    "MAX_PATIENT=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d08500ad-4524-49af-a2e7-7b7a422b96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.optimizers import SGD\n",
    "#sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36bbf54d-845d-49f7-ab37-6c200f412184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Start---------please Wait\n",
      "Epoch 1/150\n",
      "99/99 [==============================] - 322s 3s/step - loss: 0.9278 - accuracy: 0.6995 - val_loss: 4.2113 - val_accuracy: 0.1005\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.21131, saving model to efficientnetB0_100x100.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "99/99 [==============================] - 339s 3s/step - loss: 0.4113 - accuracy: 0.8697 - val_loss: 2.8875 - val_accuracy: 0.1075\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.21131 to 2.88747, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 3/150\n",
      "99/99 [==============================] - 318s 3s/step - loss: 0.3059 - accuracy: 0.9074 - val_loss: 3.1156 - val_accuracy: 0.1011\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.88747\n",
      "Epoch 4/150\n",
      "99/99 [==============================] - 321s 3s/step - loss: 0.2104 - accuracy: 0.9333 - val_loss: 2.8627 - val_accuracy: 0.0967\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.88747 to 2.86269, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 5/150\n",
      "99/99 [==============================] - 350s 4s/step - loss: 0.1748 - accuracy: 0.9469 - val_loss: 5.2346 - val_accuracy: 0.1005\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.86269\n",
      "Epoch 6/150\n",
      "99/99 [==============================] - 475s 5s/step - loss: 0.1934 - accuracy: 0.9378 - val_loss: 2.5964 - val_accuracy: 0.1469\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.86269 to 2.59644, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 7/150\n",
      "99/99 [==============================] - 690s 7s/step - loss: 0.1407 - accuracy: 0.9551 - val_loss: 5.0528 - val_accuracy: 0.1196\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.59644\n",
      "Epoch 8/150\n",
      "99/99 [==============================] - 695s 7s/step - loss: 0.1331 - accuracy: 0.9593 - val_loss: 3.5404 - val_accuracy: 0.0483\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.59644\n",
      "Epoch 9/150\n",
      "99/99 [==============================] - 667s 7s/step - loss: 0.1245 - accuracy: 0.9626 - val_loss: 54.6769 - val_accuracy: 0.1088\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.59644\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/150\n",
      "99/99 [==============================] - 617s 6s/step - loss: 0.0573 - accuracy: 0.9822 - val_loss: 2.2326 - val_accuracy: 0.3162\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.59644 to 2.23263, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 11/150\n",
      "99/99 [==============================] - 582s 6s/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 1.2520 - val_accuracy: 0.6838\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.23263 to 1.25200, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 12/150\n",
      "99/99 [==============================] - 584s 6s/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.5811 - val_accuracy: 0.8384\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.25200 to 0.58110, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 13/150\n",
      "99/99 [==============================] - 651s 7s/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.1922 - val_accuracy: 0.9447\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.58110 to 0.19218, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 14/150\n",
      "99/99 [==============================] - 652s 7s/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.3667 - val_accuracy: 0.9065\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19218\n",
      "Epoch 15/150\n",
      "99/99 [==============================] - 356s 4s/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.5818 - val_accuracy: 0.8550\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19218\n",
      "Epoch 16/150\n",
      "99/99 [==============================] - 341s 3s/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.4074 - val_accuracy: 0.8963\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19218\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 17/150\n",
      "99/99 [==============================] - 327s 3s/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.1769 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.19218 to 0.17693, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 18/150\n",
      "99/99 [==============================] - 315s 3s/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.1630 - val_accuracy: 0.9574\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.17693 to 0.16298, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 19/150\n",
      "99/99 [==============================] - 349s 4s/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1521 - val_accuracy: 0.9587\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16298 to 0.15212, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 20/150\n",
      "99/99 [==============================] - 369s 4s/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.1502 - val_accuracy: 0.9567\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15212 to 0.15021, saving model to efficientnetB0_100x100.h5\n",
      "Epoch 21/150\n",
      "99/99 [==============================] - 371s 4s/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.1513 - val_accuracy: 0.9587\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15021\n",
      "Epoch 22/150\n",
      "99/99 [==============================] - 371s 4s/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1787 - val_accuracy: 0.9529\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15021\n",
      "Epoch 23/150\n",
      "99/99 [==============================] - 371s 4s/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1556 - val_accuracy: 0.9587\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15021\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 24/150\n",
      "99/99 [==============================] - 370s 4s/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.1514 - val_accuracy: 0.9599\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15021\n",
      "Epoch 25/150\n",
      "99/99 [==============================] - 426s 4s/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1509 - val_accuracy: 0.9599\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15021\n",
      "[INFO] Training Finished!!!\n",
      "Wall time: 3h 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "opt = tf.optimizers.Adam(0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('efficientnetB0_100x100.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=MAX_PATIENT)\n",
    "ReduceLR = ReduceLROnPlateau(monitpr = 'val_loss',factor=0.1,patience=3, verbose=1)\n",
    "callbacks_list = [checkpoint,ReduceLR, early]\n",
    "\n",
    "print(\"[INFO] Training Start---------please Wait\")\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs, \n",
    "                    validation_data =(x_val, y_val),\n",
    "                    verbose = 1,\n",
    "                   callbacks = callbacks_list)\n",
    "print(\"[INFO] Training Finished!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d350c165-8117-434e-be9b-405eb9ce5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 87s 876ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "training score:  [0.0015850483905524015, 1.0]\n",
      "25/25 [==============================] - 19s 770ms/step - loss: 0.1509 - accuracy: 0.9599\n",
      "validation score:  [0.15094713866710663, 0.9599236845970154]\n",
      "14/14 [==============================] - 11s 762ms/step - loss: 0.1683 - accuracy: 0.9657\n",
      "test score:  [0.16826903820037842, 0.9656750559806824]\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_train, y_train, batch_size = 64)\n",
    "print('training score: ', score)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, batch_size = 64)\n",
    "print('validation score: ', score)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size = 64)\n",
    "print('test score: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1919d4-27e3-42c3-8018-a8bd7cef35d7",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d38109b-d4f8-4132-9c1e-45b8a5a27dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 4, 4, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 20480)             0         \n",
      "=================================================================\n",
      "Total params: 4,049,571\n",
      "Trainable params: 4,007,548\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 4, 4, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 20480)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               5243136   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,326,893\n",
      "Trainable params: 9,284,870\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining the model\n",
    "base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=x_train.shape[1:],classes=y_train.shape[1])\n",
    "\n",
    "#Adding the final layers to the above base models where the actual classification is done in the dense layers\n",
    "\n",
    "model= Sequential()\n",
    "model.add(base_model) \n",
    "model.add(Flatten()) \n",
    "\n",
    "#Model summary\n",
    "model.summary()\n",
    "\n",
    "#Adding the Dense layers along with activation and batch normalization\n",
    "#model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "#model.add(Dropout(.5))\n",
    "#model.add(Dense(512,activation=('relu'))) \n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "#model.add(Dropout(.3))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(Dense(10,activation=('softmax'))) \n",
    "\n",
    "#Checking the final model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77455708-3e16-4865-8130-9c554ebb61c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Start---------please Wait\n",
      "Epoch 1/150\n",
      "99/99 [==============================] - 417s 4s/step - loss: 1.6138 - accuracy: 0.5465 - val_loss: 4.3414 - val_accuracy: 0.1221\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.34139, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 2/150\n",
      "99/99 [==============================] - 347s 4s/step - loss: 0.8063 - accuracy: 0.7486 - val_loss: 11.6950 - val_accuracy: 0.0483\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.34139\n",
      "Epoch 3/150\n",
      "99/99 [==============================] - 322s 3s/step - loss: 0.6656 - accuracy: 0.7954 - val_loss: 3.0136 - val_accuracy: 0.0585\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.34139 to 3.01357, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 4/150\n",
      "99/99 [==============================] - 336s 3s/step - loss: 0.4870 - accuracy: 0.8541 - val_loss: 5.5597 - val_accuracy: 0.1005\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.01357\n",
      "Epoch 5/150\n",
      "99/99 [==============================] - 310s 3s/step - loss: 0.4124 - accuracy: 0.8823 - val_loss: 5.4582 - val_accuracy: 0.1221\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.01357\n",
      "Epoch 6/150\n",
      "99/99 [==============================] - 310s 3s/step - loss: 0.3895 - accuracy: 0.8874 - val_loss: 4.4412 - val_accuracy: 0.1858\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.01357\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0004999999888241291.\n",
      "Epoch 7/150\n",
      "99/99 [==============================] - 310s 3s/step - loss: 0.1810 - accuracy: 0.9458 - val_loss: 2.9571 - val_accuracy: 0.2468\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.01357 to 2.95710, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 8/150\n",
      "99/99 [==============================] - 309s 3s/step - loss: 0.1108 - accuracy: 0.9663 - val_loss: 3.2472 - val_accuracy: 0.3651\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.95710\n",
      "Epoch 9/150\n",
      "99/99 [==============================] - 309s 3s/step - loss: 0.0894 - accuracy: 0.9728 - val_loss: 2.9513 - val_accuracy: 0.3543\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.95710 to 2.95130, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 10/150\n",
      "99/99 [==============================] - 309s 3s/step - loss: 0.0705 - accuracy: 0.9776 - val_loss: 1.1891 - val_accuracy: 0.6813\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.95130 to 1.18912, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 11/150\n",
      "99/99 [==============================] - 319s 3s/step - loss: 0.0616 - accuracy: 0.9801 - val_loss: 2.0173 - val_accuracy: 0.5095\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.18912\n",
      "Epoch 12/150\n",
      "99/99 [==============================] - 321s 3s/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 5.2695 - val_accuracy: 0.3302\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.18912\n",
      "Epoch 13/150\n",
      "99/99 [==============================] - 317s 3s/step - loss: 0.0400 - accuracy: 0.9882 - val_loss: 1.3701 - val_accuracy: 0.6228\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.18912\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n",
      "Epoch 14/150\n",
      "99/99 [==============================] - 399s 4s/step - loss: 0.0296 - accuracy: 0.9924 - val_loss: 0.5137 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.18912 to 0.51367, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 15/150\n",
      "99/99 [==============================] - 375s 4s/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.3089 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.51367 to 0.30887, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 16/150\n",
      "99/99 [==============================] - 363s 4s/step - loss: 0.0314 - accuracy: 0.9898 - val_loss: 1.3723 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.30887\n",
      "Epoch 17/150\n",
      "99/99 [==============================] - 357s 4s/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.1771 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.30887 to 0.17715, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 18/150\n",
      "99/99 [==============================] - 475s 5s/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 2.7104 - val_accuracy: 0.6406\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.17715\n",
      "Epoch 19/150\n",
      "99/99 [==============================] - 486s 5s/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.9688 - val_accuracy: 0.8149\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.17715\n",
      "Epoch 20/150\n",
      "99/99 [==============================] - 338s 3s/step - loss: 0.0258 - accuracy: 0.9925 - val_loss: 0.3090 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17715\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999509891496e-06.\n",
      "Epoch 21/150\n",
      "99/99 [==============================] - 330s 3s/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.1739 - val_accuracy: 0.9510\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.17715 to 0.17387, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 22/150\n",
      "99/99 [==============================] - 330s 3s/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.1509 - val_accuracy: 0.9555\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.17387 to 0.15092, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 23/150\n",
      "99/99 [==============================] - 363s 4s/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.1470 - val_accuracy: 0.9593\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15092 to 0.14697, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 24/150\n",
      "99/99 [==============================] - 350s 4s/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.1453 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14697 to 0.14532, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 25/150\n",
      "99/99 [==============================] - 415s 4s/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 0.1464 - val_accuracy: 0.9625\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14532\n",
      "Epoch 26/150\n",
      "99/99 [==============================] - 390s 4s/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.1446 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.14532 to 0.14455, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 27/150\n",
      "99/99 [==============================] - 388s 4s/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.1518 - val_accuracy: 0.9555\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14455\n",
      "Epoch 28/150\n",
      "99/99 [==============================] - 371s 4s/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.1431 - val_accuracy: 0.9593\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14455 to 0.14308, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 29/150\n",
      "99/99 [==============================] - 337s 3s/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.1512 - val_accuracy: 0.9555\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14308\n",
      "Epoch 30/150\n",
      "99/99 [==============================] - 338s 3s/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.1412 - val_accuracy: 0.9599\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.14308 to 0.14116, saving model to efficientnetB0-2_100x100.h5\n",
      "Epoch 31/150\n",
      "99/99 [==============================] - 326s 3s/step - loss: 0.0239 - accuracy: 0.9940 - val_loss: 0.1444 - val_accuracy: 0.9593\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14116\n",
      "Epoch 32/150\n",
      "99/99 [==============================] - 343s 3s/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.1435 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14116\n",
      "Epoch 33/150\n",
      "99/99 [==============================] - 370s 4s/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.1483 - val_accuracy: 0.9574\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.14116\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.999999418942025e-07.\n",
      "Epoch 34/150\n",
      "99/99 [==============================] - 440s 4s/step - loss: 0.0211 - accuracy: 0.9943 - val_loss: 0.1434 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14116\n",
      "Epoch 35/150\n",
      "99/99 [==============================] - 450s 5s/step - loss: 0.0222 - accuracy: 0.9946 - val_loss: 0.1425 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14116\n",
      "[INFO] Training Finished!!!\n",
      "Wall time: 3h 30min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Defining the parameters\n",
    "batch_size= 64\n",
    "epochs=150\n",
    "lr=.005\n",
    "MAX_PATIENT=5\n",
    "\n",
    "opt = tf.optimizers.Adam(lr)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('efficientnetB0-2_100x100.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=MAX_PATIENT)\n",
    "ReduceLR = ReduceLROnPlateau(monitpr = 'val_loss',factor=0.1,patience=3, verbose=1)\n",
    "callbacks_list = [checkpoint,ReduceLR, early]\n",
    "\n",
    "print(\"[INFO] Training Start---------please Wait\")\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs, \n",
    "                    validation_data =(x_val, y_val),\n",
    "                    verbose = 1,\n",
    "                   callbacks = callbacks_list)\n",
    "print(\"[INFO] Training Finished!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a669c-9181-49a7-969e-0958d4df717b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/99 [==================>...........] - ETA: 30s - loss: 0.0099 - accuracy: 0.9980"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_train, y_train, batch_size = 64)\n",
    "print('training score: ', score)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, batch_size = 64)\n",
    "print('validation score: ', score)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size = 64)\n",
    "print('test score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e811333-16cf-4eae-aebf-ba2bdc237348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "fb966195-0041-4189-9f8d-af43a195bc53",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "%%time\n",
    "#Compiling the model\n",
    "#opt = optimizers.Adam(0.001)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "\n",
    "checkpoint = ModelCheckpoint('efficientnetB0_.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)\n",
    "ReduceLR = ReduceLROnPlateau(monitpr = 'val_loss',factor=0.1,patience=3, verbose=1)\n",
    "callbacks_list = [checkpoint,ReduceLR, early]\n",
    "model.fit(train_generator.flow(x_train, y_train,batch_size = batch_size),\n",
    "          epochs = epochs,\n",
    "          steps_per_epoch = x_train.shape[0]//batch_size,\n",
    "          validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size),\n",
    "          validation_steps = x_val.shape[0]//batch_size, \n",
    "          callbacks = callbacks_list, verbose = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46c57a04-6b7e-4cab-bca7-0131575129b9",
   "metadata": {},
   "source": [
    "%%time\n",
    "score = model.evaluate(x_train, y_train, batch_size = 64)\n",
    "print('training score: ', score)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, batch_size = 64)\n",
    "print('validation score: ', score)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size = 64)\n",
    "print('test score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3397409-53b3-4c94-aa20-67ca4aa1ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plotting the training and validation loss\n",
    "\n",
    "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
    "\n",
    "#Assigning the first subplot to graph training loss and validation loss\n",
    "ax[0].plot(history.history['loss'],color='b',label='Training Loss')\n",
    "ax[0].plot(history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Plotting the training accuracy and validation accuracy\n",
    "ax[1].plot(history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax[1].plot(history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142fea17-9037-42cd-9c82-df6530d63420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
