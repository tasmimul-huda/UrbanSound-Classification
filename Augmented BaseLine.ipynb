{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994d70df-447f-46da-a6f9-cfc8b424ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd025244-cf72-4c1b-8c43-14489de925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"D:/THESIS/Augmented Spectrogram/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0553a1d-e8b2-42c6-9c28-11d258822f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_conditioner',\n",
       " 'car_horn',\n",
       " 'children_playing',\n",
       " 'dog_bark',\n",
       " 'drilling',\n",
       " 'engine_idling',\n",
       " 'gun_shot',\n",
       " 'jackhammer',\n",
       " 'siren',\n",
       " 'street_music']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = os.listdir(DATADIR)\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f3eba4-19f9-4a79-999a-befe2ad75c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c55626-9280-4130-97bb-806b07537724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "761cebc0-bc5c-442a-9c3c-ed92fbda2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def create_dataset():\n",
    "    for category in categories:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = categories.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                #rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                new_array =img_array[34:252, 53:389]\n",
    "                #print(new_array.shape)\n",
    "                rsz=cv2.resize(new_array, (100, 100))\n",
    "                #print(rsz.shape)\n",
    "                data.append([rsz, class_num])  # add this to our training_data\n",
    "                #plt.axis('off')\n",
    "                #plt.imshow(rsz)\n",
    "                #plt.savefig(\"ragresize.png\")\n",
    "                #break\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e30d1e-eb10-4497-b5b3-88fc193548d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:14<00:00, 54.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1716/1716 [00:30<00:00, 56.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:15<00:00, 53.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:23<00:00, 47.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:14<00:00, 53.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:09<00:00, 57.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1496/1496 [00:23<00:00, 64.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:14<00:00, 53.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3716/3716 [01:07<00:00, 55.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [01:09<00:00, 57.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34928\n",
      "Wall time: 10min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = create_dataset()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b6870e-d605-4a14-a18f-18e5c8f7c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f52e970-4a64-436b-a9e8-2427e15d4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd272621-3aca-4911-8566-1b92e3845e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X_DATA_augment_100x100_1.pickle\",\"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y_DATA_augment_100x100_1.pickle\",\"wb\")\n",
    "pickle.dump(Y,pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39a8c124-d0fe-43fe-81c8-bf13626c4594",
   "metadata": {},
   "source": [
    "X = pickle.load(open(\"X_DATA_augment_100x100_1.pickle\",'rb'))\n",
    "Y = pickle.load(open(\"Y_DATA_augment_100x100_1.pickle\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0758932-7977-4da3-8b0d-0fcd69810bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4155bed6-891f-45c5-a057-91dba746f41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34928, 100, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e01311-5263-41cc-89df-ad0d86a95430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f35514-8f6f-46ba-9ccb-1a6d7f4ed945",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, X_test, Y_data, Y_test = train_test_split(X, Y,test_size=0.10, random_state = 41,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7fd8265-8ca4-4916-beea-fd104e6da513",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val, Y_train, Y_val = train_test_split(X_data, Y_data,test_size=0.20, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345fe691-6a3d-4641-96fc-3c36f8b783f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizaze_data(X):\n",
    "    X_data = []\n",
    "    for data in X:\n",
    "        data = data / 255\n",
    "        X_data.append(data)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479db90-c8b5-436b-8a73-d55f6db97951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = normalizaze_data(X_train)\n",
    "x_val = normalizaze_data(X_val)\n",
    "x_test = normalizaze_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f186f-b4be-45c9-b672-01ee84ea4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 100, 100, 1)\n",
    "x_val = x_val.reshape(-1, 100, 100, 1)\n",
    "x_test = x_test.reshape(-1, 100, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1df50-d25c-47bd-8f70-a92210b376e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_train =to_categorical(Y_train)\n",
    "y_val = to_categorical(Y_val)\n",
    "y_test =to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3f2e5-0c4f-418a-9b65-547904da3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bde9b-89f3-484b-847f-2b6c93027bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e71c96-2c68-48f4-bda9-997f198d9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train.shape: {x_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"x_val.shape: {x_val.shape}\")\n",
    "print(f\"y_val.shape: {y_val.shape}\")\n",
    "print(f\"x_test.shape: {x_test.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188afb8-7452-4197-a74e-ac881e144a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43de1f5-5c5a-40d2-9955-e0eef0fa99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing other required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import losses, models, optimizers\n",
    "import time\n",
    "from tensorflow.keras.layers import Input,Dense, Dropout, Activation, Flatten,concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import (Convolution2D, Dense,Flatten, Dropout, GlobalAveragePooling2D,GlobalMaxPool2D, \n",
    "                          Input, MaxPool2D, concatenate)\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66882344-4c81-4af4-bc90-cbcbb1a7fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train.shape: {x_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"x_val.shape: {x_val.shape}\")\n",
    "print(f\"y_val.shape: {y_val.shape}\")\n",
    "print(f\"x_val.shape: {x_test.shape}\")\n",
    "print(f\"y_val.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cef234-b8d4-4ae6-a63e-79918188b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2e349-1a5b-42a3-a7bc-cf2b269cb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1:]\n",
    "num_class = 10\n",
    "MAX_PATIENT =5\n",
    "MAX_EPOCHS = 150\n",
    "batch_size = 64\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977bc46-4951-4bb5-9226-549a5e9d5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def CNN_Baseline(input_dim,num_class):\n",
    "    inputs = Input(shape=input_dim)\n",
    "    x = Convolution2D(64, (3, 3), activation = \"relu\") (inputs)\n",
    "    x = MaxPool2D(pool_size=(2, 2)) (x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    \n",
    "    x = Convolution2D(128, (3, 3), activation = \"relu\") (x)\n",
    "    x = MaxPool2D(pool_size=(2, 2)) (x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "   \n",
    "    x = Convolution2D(128, (3, 3), activation = \"relu\") (x)\n",
    "    x = MaxPool2D(pool_size=(2, 2)) (x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(100, activation = \"relu\") (x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    outputs = Dense(num_class, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model \n",
    "\n",
    "model = CNN_Baseline(input_dim,num_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d708e-b866-4c0a-abd0-b54ef6cb04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "from datetime import datetime\n",
    "import keras\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cea821-db6e-4901-af20-544f79dc9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(lr)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('Models/model_seed_41__.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=MAX_PATIENT)\n",
    "ReduceLR = ReduceLROnPlateau(monitpr = 'val_loss',factor=0.1,patience=3, verbose=1)\n",
    "callbacks_list = [checkpoint,ReduceLR, early,tensorboard_callback]\n",
    "\n",
    "print(\"[INFO] Training Start---------please Wait\")\n",
    "history_1 = model.fit(x_train, y_train, \n",
    "                    batch_size = batch_size,epochs = MAX_EPOCHS, \n",
    "                    validation_data =(x_val, y_val),\n",
    "                    verbose = 1,callbacks = callbacks_list)\n",
    "print(\"[INFO] Training Finished!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af174857-2467-4567-9b38-13600499b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350c165-8117-434e-be9b-405eb9ce5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_train, y_train, batch_size = 64)\n",
    "print('training score: ', score)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, batch_size = 64)\n",
    "print('validation score: ', score)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size = 64)\n",
    "print('test score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78a323-9ab1-4595-b792-7898599da6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb90e8-4ac6-4666-87b3-6629edaa5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619baa1-91d2-4e1d-bcc3-d53f3d3472e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(history,fig_name):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.grid()\n",
    "    plt.title('Training and validation Curve')\n",
    "    plt.plot(epochs, acc, 'b',marker='o', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r',marker='o', label='Validation acc')\n",
    "    plt.legend()\n",
    "    plt.plot(epochs, loss, 'm',marker='o', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'g',marker='o', label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"Figures/{fig_name}.png\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394e926-08f0-402b-a29b-9e7a3cc15abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(history_1,'fig_name_41')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4128017-d21a-4263-bd2a-40b01bf65e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(y_true, y_pred, figsize=(10,10)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    # cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm = pd.DataFrame(cm, index=[i for i in class_names],\n",
    "                  columns = [i for i in class_names])\n",
    "    \n",
    "    cm.index.name = 'True label'\n",
    "    cm.columns.name = 'Predicted label'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388bdcc-b371-46b0-abd3-232eae98c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['air_conditioner','car_horn','children_playing','dog_bark','drilling','engine_idling',\n",
    "                      'gun_shot','jackhammer','siren','street_music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbc5ef-47b0-491a-bcf3-9164666f0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = model.predict(x_test)\n",
    "model_predicted_label = np.argmax(model_predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a7598-1b77-4060-b0bb-524b6e29fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predicted_label[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c51b1-0dfc-4ecb-ba4e-a33ebfbd44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70503ef0-4d48-4ec1-9850-c3796fe102fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(test_label, model_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44298fe5-45e1-4831-aad9-573880020000",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3f183-f431-42f8-92e7-0d5b54d695f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67383988-4b92-48e1-8595-0e358bc3329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d54180-34d5-4719-817d-7a3f6ddfa1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, model_predicted_label, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2188e-be4d-408b-b269-bd444f4299f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "target= class_names\n",
    "\n",
    "# set plot figure size\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (16, 16))\n",
    "\n",
    "# function for scoring roc auc score for multi-class\n",
    "def multiclass_roc_auc_score(y_true, model_predicted_label, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_true)\n",
    "    y_test = lb.transform(y_true)\n",
    "    y_pred = lb.transform(model_predicted_label)\n",
    "\n",
    "    for (idx, c_label) in enumerate(target):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "\n",
    "print('ROC AUC score:', multiclass_roc_auc_score(y_true, model_predicted_label))\n",
    "\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94216c-ab5b-40d7-8d89-7ae67ea09f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
